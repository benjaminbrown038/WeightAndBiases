{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlBCnN4FFaDyykJ4NbTLSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/WeightAndBiases/blob/main/notebooks/xgboost/xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FCHhB8jqFnN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Rh4_KwxAFnQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -qq wandb>=0.13.10 dill\n",
        "!pip install -qq xgboost>=1.7.4 scikit-learn>=1.2.1"
      ],
      "metadata": {
        "id": "iW_0simcFmXD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jFm92iGYFpCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import ast\n",
        "import sys\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dill.source import getsource\n",
        "from dill import detect\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import ks_2samp\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "import xgboost as xgb\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)"
      ],
      "metadata": {
        "id": "ci0jsbFYFmZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KKrKiElqFpiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "artifact = wandb.Artifact(\"mnist\", type=\"dataset\")\n",
        "artifact.add_reference(\"s3://my-bucket/datasets/mnist\")\n",
        "run.log_artifact(artifact)"
      ],
      "metadata": {
        "id": "MFucY1hPFmcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Al9tfzkvFqCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "artifact = run.use_artifact(\"mnist:latest\", type=\"dataset\")\n",
        "artifact_dir = artifact.download()"
      ],
      "metadata": {
        "id": "68cMSETOFmfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fdyLMD6NFqti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "WANDB_PROJECT = \"vehicle_loan_default\""
      ],
      "metadata": {
        "id": "w1jWMTTQFmh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify a folder to save the data, a new folder will be created if it doesn't exist\n",
        "data_dir = Path(\".\")\n",
        "model_dir = Path(\"models\")\n",
        "model_dir.mkdir(exist_ok=True)\n",
        "\n",
        "id_vars = [\"UniqueID\"]\n",
        "targ_var = \"loan_default\""
      ],
      "metadata": {
        "id": "HOZvmSYfFmki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def function_to_string(fn):\n",
        "    return getsource(detect.code(fn))"
      ],
      "metadata": {
        "id": "f1y19V4XFmna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=WANDB_PROJECT, job_type=\"preprocess-data\")"
      ],
      "metadata": {
        "id": "kTH6oKx4FmqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_utils import (\n",
        "    describe_data_g_targ,\n",
        "    one_hot_encode_data,\n",
        "    load_training_data,\n",
        ")"
      ],
      "metadata": {
        "id": "KgcytjF-FmtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data into Dataframe\n",
        "dataset = pd.read_csv(data_dir / \"vehicle_loans_subset.csv\")\n",
        "\n",
        "# One Hot Encode Data\n",
        "dataset, p_vars = one_hot_encode_data(dataset, id_vars, targ_var)\n",
        "\n",
        "# Save Preprocessed data\n",
        "processed_data_path = data_dir / \"proc_ds.csv\"\n",
        "dataset.to_csv(processed_data_path, index=False)"
      ],
      "metadata": {
        "id": "UvGE0WpvFmvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
        "processed_ds_art = wandb.Artifact(\n",
        "    name=\"vehicle_defaults_processed\",\n",
        "    type=\"processed_dataset\",\n",
        "    description=\"One-hot encoded dataset\",\n",
        "    metadata={\"preprocessing_fn\": function_to_string(one_hot_encode_data)},\n",
        ")\n",
        "\n",
        "# Attach our processed data to the Artifact\n",
        "processed_ds_art.add_file(processed_data_path)\n",
        "\n",
        "# Log this Artifact to the current wandb run\n",
        "run.log_artifact(processed_ds_art)\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "L_o7grD0FmyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
        "processed_ds_art = wandb.Artifact(\n",
        "    name=\"vehicle_defaults_processed\",\n",
        "    type=\"processed_dataset\",\n",
        "    description=\"One-hot encoded dataset\",\n",
        "    metadata={\"preprocessing_fn\": function_to_string(one_hot_encode_data)},\n",
        ")\n",
        "\n",
        "# Attach our processed data to the Artifact\n",
        "processed_ds_art.add_file(processed_data_path)\n",
        "\n",
        "# Log this Artifact to the current wandb run\n",
        "run.log_artifact(processed_ds_art)\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "c-AyX63LF-Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with wandb.init(\n",
        "    project=WANDB_PROJECT, job_type=\"train-val-split\"\n",
        ") as run:  # config is optional here\n",
        "    # Download the subset of the vehicle loan default data from W&B\n",
        "    dataset_art = run.use_artifact(\n",
        "        \"vehicle_defaults_processed:latest\", type=\"processed_dataset\"\n",
        "    )\n",
        "    dataset_dir = dataset_art.download(data_dir)\n",
        "    dataset = pd.read_csv(processed_data_path)\n",
        "\n",
        "    # Set Split Params\n",
        "    test_size = 0.25\n",
        "    random_state = 42\n",
        "\n",
        "    # Log the splilt params\n",
        "    run.config.update({\"test_size\": test_size, \"random_state\": random_state})\n",
        "\n",
        "    # Do the Train/Val Split\n",
        "    trndat, valdat = model_selection.train_test_split(\n",
        "        dataset,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=dataset[[targ_var]],\n",
        "    )\n",
        "\n",
        "    print(f\"Train dataset size: {trndat[targ_var].value_counts()} \\n\")\n",
        "    print(f\"Validation dataset sizeL {valdat[targ_var].value_counts()}\")\n",
        "\n",
        "    # Save split datasets\n",
        "    train_path = data_dir / \"train.csv\"\n",
        "    val_path = data_dir / \"val.csv\"\n",
        "    trndat.to_csv(train_path, index=False)\n",
        "    valdat.to_csv(val_path, index=False)\n",
        "\n",
        "    # Create a new artifact for the processed data, including the function that created it, to Artifacts\n",
        "    split_ds_art = wandb.Artifact(\n",
        "        name=\"vehicle_defaults_split\",\n",
        "        type=\"train-val-dataset\",\n",
        "        description=\"Processed dataset split into train and valiation\",\n",
        "        metadata={\"test_size\": test_size, \"random_state\": random_state},\n",
        "    )\n",
        "\n",
        "    # Attach our processed data to the Artifact\n",
        "    split_ds_art.add_file(train_path)\n",
        "    split_ds_art.add_file(val_path)\n",
        "\n",
        "    # Log the Artifact\n",
        "    run.log_artifact(split_ds_art)"
      ],
      "metadata": {
        "id": "9WD3TU2JF-Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trndict = describe_data_g_targ(trndat, targ_var)\n",
        "trndat.head()"
      ],
      "metadata": {
        "id": "c1d8B7QaF-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a wandb run, with an optional \"log-dataset\" job type to keep things tidy\n",
        "run = wandb.init(\n",
        "    project=WANDB_PROJECT, job_type=\"log-dataset\"\n",
        ")  # config is optional here\n",
        "\n",
        "# Create a W&B Table and log 1000 random rows of the dataset to explore\n",
        "table = wandb.Table(dataframe=trndat.sample(1000))\n",
        "\n",
        "# Log the Table to your W&B workspace\n",
        "wandb.log({\"processed_dataset\": table})\n",
        "\n",
        "# Close the wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "XBSQ9e2RF-Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"tree_method\": \"gpu_hist\""
      ],
      "metadata": {
        "id": "uT93M1fEF-Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=WANDB_PROJECT, job_type=\"train-model\")"
      ],
      "metadata": {
        "id": "Bbhx_uDdF-Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_rate = round(trndict[\"base_rate\"], 6)\n",
        "early_stopping_rounds = 40"
      ],
      "metadata": {
        "id": "mcMGtOwqF-ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bst_params = {\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"base_score\": base_rate,\n",
        "    \"gamma\": 1,  ## def: 0\n",
        "    \"learning_rate\": 0.1,  ## def: 0.1\n",
        "    \"max_depth\": 3,\n",
        "    \"min_child_weight\": 100,  ## def: 1\n",
        "    \"n_estimators\": 25,\n",
        "    \"nthread\": 24,\n",
        "    \"random_state\": 42,\n",
        "    \"reg_alpha\": 0,\n",
        "    \"reg_lambda\": 0,  ## def: 1\n",
        "    \"eval_metric\": [\"auc\", \"logloss\"],\n",
        "    \"tree_method\": \"hist\",  # use `gpu_hist` to train on GPU\n",
        "}"
      ],
      "metadata": {
        "id": "rluOH42dF-eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.config.update(dict(bst_params))\n",
        "run.config.update({\"early_stopping_rounds\": early_stopping_rounds})"
      ],
      "metadata": {
        "id": "zYXewQx5F-hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load our training data from Artifacts\n",
        "trndat, valdat = load_training_data(\n",
        "    run=run, data_dir=data_dir, artifact_name=\"vehicle_defaults_split:latest\"\n",
        ")\n",
        "\n",
        "## Extract target column as a series\n",
        "y_trn = trndat.loc[:, targ_var].astype(int)\n",
        "y_val = valdat.loc[:, targ_var].astype(int)"
      ],
      "metadata": {
        "id": "zI5BY6hrF-kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wandb.xgboost import WandbCallback\n",
        "\n",
        "# Initialize the XGBoostClassifier with the WandbCallback\n",
        "xgbmodel = xgb.XGBClassifier(\n",
        "    **bst_params,\n",
        "    callbacks=[WandbCallback(log_model=True)],\n",
        "    early_stopping_rounds=run.config[\"early_stopping_rounds\"]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "xgbmodel.fit(trndat[p_vars], y_trn, eval_set=[(valdat[p_vars], y_val)])"
      ],
      "metadata": {
        "id": "-vzcCegPF-nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bstr = xgbmodel.get_booster()\n",
        "\n",
        "# Get train and validation predictions\n",
        "trnYpreds = xgbmodel.predict_proba(trndat[p_vars])[:, 1]\n",
        "valYpreds = xgbmodel.predict_proba(valdat[p_vars])[:, 1]\n",
        "\n",
        "# Log additional Train metrics\n",
        "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
        "    y_trn, trnYpreds\n",
        ")\n",
        "run.summary[\"train_ks_stat\"] = max(true_positive_rate - false_positive_rate)\n",
        "run.summary[\"train_auc\"] = metrics.auc(false_positive_rate, true_positive_rate)\n",
        "run.summary[\"train_log_loss\"] = -(\n",
        "    y_trn * np.log(trnYpreds) + (1 - y_trn) * np.log(1 - trnYpreds)\n",
        ").sum() / len(y_trn)\n",
        "\n",
        "# Log additional Validation metrics\n",
        "ks_stat, ks_pval = ks_2samp(valYpreds[y_val == 1], valYpreds[y_val == 0])\n",
        "run.summary[\"val_ks_2samp\"] = ks_stat\n",
        "run.summary[\"val_ks_pval\"] = ks_pval\n",
        "run.summary[\"val_auc\"] = metrics.roc_auc_score(y_val, valYpreds)\n",
        "run.summary[\"val_acc_0.5\"] = metrics.accuracy_score(\n",
        "    y_val, np.where(valYpreds >= 0.5, 1, 0)\n",
        ")\n",
        "run.summary[\"val_log_loss\"] = -(\n",
        "    y_val * np.log(valYpreds) + (1 - y_val) * np.log(1 - valYpreds)\n",
        ").sum() / len(y_val)"
      ],
      "metadata": {
        "id": "yK0h9x4xF-pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the ROC curve to W&B\n",
        "valYpreds_2d = np.array([1 - valYpreds, valYpreds])  # W&B expects a 2d array\n",
        "y_val_arr = y_val.values\n",
        "d = 0\n",
        "while len(valYpreds_2d.T) > 10000:\n",
        "    d += 1\n",
        "    valYpreds_2d = valYpreds_2d[::1, ::d]\n",
        "    y_val_arr = y_val_arr[::d]\n",
        "\n",
        "run.log(\n",
        "    {\n",
        "        \"ROC_Curve\": wandb.plot.roc_curve(\n",
        "            y_val_arr,\n",
        "            valYpreds_2d.T,\n",
        "            labels=[\"no_default\", \"loan_default\"],\n",
        "            classes_to_plot=[1],\n",
        "        )\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "lgpvgQSOF-sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "xAT7ZLHAGPDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"random\",\n",
        "    \"parameters\": {\n",
        "        \"learning_rate\": {\"min\": 0.001, \"max\": 1.0},\n",
        "        \"gamma\": {\"min\": 0.001, \"max\": 1.0},\n",
        "        \"min_child_weight\": {\"min\": 1, \"max\": 150},\n",
        "        \"early_stopping_rounds\": {\"values\": [10, 20, 30, 40]},\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT)"
      ],
      "metadata": {
        "id": "ELyCOSufGPGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    with wandb.init(job_type=\"sweep\") as run:\n",
        "        bst_params = {\n",
        "            \"objective\": \"binary:logistic\",\n",
        "            \"base_score\": base_rate,\n",
        "            \"gamma\": run.config[\"gamma\"],\n",
        "            \"learning_rate\": run.config[\"learning_rate\"],\n",
        "            \"max_depth\": 3,\n",
        "            \"min_child_weight\": run.config[\"min_child_weight\"],\n",
        "            \"n_estimators\": 25,\n",
        "            \"nthread\": 24,\n",
        "            \"random_state\": 42,\n",
        "            \"reg_alpha\": 0,\n",
        "            \"reg_lambda\": 0,  ## def: 1\n",
        "            \"eval_metric\": [\"auc\", \"logloss\"],\n",
        "            \"tree_method\": \"hist\",\n",
        "        }\n",
        "\n",
        "        # Initialize the XGBoostClassifier with the WandbCallback\n",
        "        xgbmodel = xgb.XGBClassifier(\n",
        "            **bst_params,\n",
        "            callbacks=[WandbCallback()],\n",
        "            early_stopping_rounds=run.config[\"early_stopping_rounds\"]\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        xgbmodel.fit(trndat[p_vars], y_trn, eval_set=[(valdat[p_vars], y_val)])\n",
        "\n",
        "        bstr = xgbmodel.get_booster()\n",
        "\n",
        "        # Log booster metrics\n",
        "        run.summary[\"best_ntree_limit\"] = bstr.best_ntree_limit\n",
        "\n",
        "        # Get train and validation predictions\n",
        "        trnYpreds = xgbmodel.predict_proba(trndat[p_vars])[:, 1]\n",
        "        valYpreds = xgbmodel.predict_proba(valdat[p_vars])[:, 1]\n",
        "\n",
        "        # Log additional Train metrics\n",
        "        false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(\n",
        "            y_trn, trnYpreds\n",
        "        )\n",
        "        run.summary[\"train_ks_stat\"] = max(true_positive_rate - false_positive_rate)\n",
        "        run.summary[\"train_auc\"] = metrics.auc(false_positive_rate, true_positive_rate)\n",
        "        run.summary[\"train_log_loss\"] = -(\n",
        "            y_trn * np.log(trnYpreds) + (1 - y_trn) * np.log(1 - trnYpreds)\n",
        "        ).sum() / len(y_trn)\n",
        "\n",
        "        # Log additional Validation metrics\n",
        "        ks_stat, ks_pval = ks_2samp(valYpreds[y_val == 1], valYpreds[y_val == 0])\n",
        "        run.summary[\"val_ks_2samp\"] = ks_stat\n",
        "        run.summary[\"val_ks_pval\"] = ks_pval\n",
        "        run.summary[\"val_auc\"] = metrics.roc_auc_score(y_val, valYpreds)\n",
        "        run.summary[\"val_acc_0.5\"] = metrics.accuracy_score(\n",
        "            y_val, np.where(valYpreds >= 0.5, 1, 0)\n",
        "        )\n",
        "        run.summary[\"val_log_loss\"] = -(\n",
        "            y_val * np.log(valYpreds) + (1 - y_val) * np.log(1 - valYpreds)\n",
        "        ).sum() / len(y_val)"
      ],
      "metadata": {
        "id": "iW7jay_NGPIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 10  # number of runs to execute\n",
        "wandb.agent(sweep_id, function=train, count=count)"
      ],
      "metadata": {
        "id": "X_KQZHw4GPLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7yYSgBMGPNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKDYCevlGPQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lC-00FXgGPT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gmolyQyTGPWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MD2KCZN5GPZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3UoS9aZGPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWKKonz0GPej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtmI10RtGPg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyCEQP69Fm1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQNHrZnmFm4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qu33wSREFm6i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}